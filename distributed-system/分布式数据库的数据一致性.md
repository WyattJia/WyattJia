# 保证分布式数据的数据一致性


## 多副本间的一致性

数据存储系统千差万别，但是保证数据库多副本之间的一致性，基本都跑不出一个办法，就是状态机复制（state machine replication）。

**稍微解释一下状态机：有限状态机的行为，只要是固定的一串输入内容，输出必然是相同的。**

因此保证 *多副本一致性* ➡️ *保证所有副本服务器的输入内容必须一致*
所有副本回放 *日志* 之后，内部存储的数据也必然是相同的，（具体实践可以参考 redis 的数据持久化方案，以及 MySQL 的 binlog 系统）

👇继续往下，

搞定状态机复制，要做两件事情：

  1. 保证消息全序 

     保证所有消息必须有严格的先后顺序，一个时间内只有一个指挥官在发出指令，自动选出 leader 节点等等。

     分布式数据的时序问题，可以参考 lamport 时间戳，以及其应用 tcp 消息传递间的 syn 值。

  2. 选择一个合适数据一致性算法 
     
     常用的有 raft paxos 等等，保证各个副本获得的日志都是严格一致的。

👇继续往下，

通过状态机复制来保证数据多副本的一致性，其中面临的一个困难是*性能*达不到要求。

主要是两个方面的性能可能会达不到要求：

  1. 底层的日志复制协议吞吐量不够高
     日志本身数据量可能过大，包含了很多数据内容，文件系统等等。
     解决办法就是，在 leader 服务器上做 pipeline ，（即不等副本返回响应，就立即发送下一批日志），但是工程量比较大，比较难实现。
  2. 上层服务器回放日志性能不够
      为保证消息全序，只能单线程回放日志，性能不够快。
      解决办法是对数据进行适当的分区，从而可以并行的回放分区，提高吞吐量


👇继续往下，


状态机复制中的*可用性*问题：

集群中 leader 服务器如果宕机，会执行重选 leader 算法，有一定的时间造成不可用，如果涉及跨机房多副本，还会带来网络分区的问题，进一步降低可用性。虽然大部分情况不会要求如此苛刻。

解决方案之一就是 Amazon 的 dynamo 系统，提升可用性，放宽数据一致性的要求。其思路是消息不完全排序，通过一个 *全局时钟(`vector clock`)* 的算法，对消息进行智能排序。



## 分布式事务带来的问题

数据一致性带来的问题，保证事务中多条记录的修改能同时成功或者同时失败，即 acid 中的 atomic 原子性，解决办法就是 2-pc ，两段提交法。

  两段提交法：
    由一个事务协调器发起两轮操作命令:
      1. 第一轮 prepare 命令询问各个参与者是否同意本次操作，
      👇 如果同意
      2. 第二轮，commit 命令，在各个参与者服务器上真正提交本次事务。

  两段提交的缺点：
    两段提交法能保证事务中多条记录的一致性，但是算法本身灵活性不足。如果某些参与者服务器出现不可用或者宕机的情况，会导致部分数据库上悬挂中间状态的事务，事务永远在 prepare 阶段中，事务包含的数据行就会被锁住。更进一步的问题是，即使发现某个数据库上 prepare 悬挂事务，也没有办法作出后续处理，因为任何后续处理都可能会造成数据不一致的情况。因此发明了*三段提交*。

    三段提交法：

      * 在两段提交的 commit 之前,再插入一个 *预提交(pre-commit)* 状态
      * 当处于预提交状态的事务,如果在等待一段时间超时后仍然没有收到后续指令,可以按照事先的约定来自行提交或者回滚事务.

      核心就是在两段提交的基础上引入了超时机制,灵感来源于 *FLP 定理* 
      简单提一下什么是 FLP 定理:
      对于一个只是依靠消息通讯的异步系统来说,如果出现了服务器异常,无论依靠什么精妙的算法,都有可能导致本次请求的各参与方处于永久的不一致状态.两部系统也是一个异步系统.但是这个定理有个前提是不能用时间作为任何超时假设...(这段暂时没有搞懂..)
      除了三段提交意外,还有另外一个简单粗暴的解决办法,让事务参与者永远不会失败,把各服务器全部都用 paxos 协议来实现(或者使用 raft 协议实现?),这两个算法本身是具有一定容错性的.
